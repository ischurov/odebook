\h1 Простейшие линейные дифференциальные уравнения \label{chap:9:linear}

\h2 Линейное и нелинейное: кто матери-теории более ценен?

\emph{Все счастливые семьи похожи друг на друга, каждая несчастливая семья несчастлива по-своему}. Л. Н. Толстой, «Анна Каренина».

В \ref[предыдущей главе\nonumber|chap:8:rect] мы выяснили, что все \snref[неособые
точки|snip:singular] похожи друг на друга: подходящей заменой координат
векторное поле в окрестности любой неособой точки превращается в постоянное
поле. Однако особые точки бывают особыми по-своему. Нашей целью теперь
является изучение особых точек.

Вообще говоря, изучение особых точек произвольных векторных полей — сложная
задача. Однако, великая наука матанализ учит нас: сложное нелинейное становится
простым и линейным, если посмотреть на него в микроскоп. Поэтому изучение
линейного — первый шаг на пути к познанию нелинейного.

Если мы хотим понять, как ведёт себя функция одной переменной вблизи некоторой точки, мы вычислим производную функции в этой точке, приблизим график функции графиком касательной (линейной частью) и скажем, что её поведение близко к поведению её линейной части. Скажем, если производная положительна, линейная часть возрастает, а значит и сама функция возрастает.

Аналогичный подход работает и в дифференциальных уравнениях.

\h3 Мотивирующий пример: изучение постоянного решения одномерного уравнения
    \label par:9:eq-in-var

Рассмотрим уравнение
\equation \label{eq:9:1d}
    \dot x=f(t, x),\quad x\in \mathbb R^1,\quad f(t, 0)\equiv 0
Иными словами, это произвольное неавтономное уравнение на прямой, обладающее
одним характерным свойством: правая часть обнуляется при $x=0$ и произвольном
$t$.

Рассмотрим функцию $x=\varphi(t; x_0)$, задающую решение уравнения \ref{eq:9:1d} с начальным условием $x(t_0) = \varphi (t_0; x_0)=x_0$. Очевидно, $\varphi(t;0)\equiv 0$: тождественно нулевая функция является единственным решением с нулевым начальным условием. (Если бы уравнение было автономным, мы бы сказали, что $0$ является особой точкой; в данном случае уравнение неавтономное и такой термин мы использовать не можем, хотя это и близкий сюжет.)

Пусть теперь нам интересно, как ведут себя решения с начальными условиями,
близкими к нулевому. Например, они могут приближаться к нулевому решению, могут
убегать от него, а могут попеременно делать то одно, то другое. Это не праздный
интерес: на практике мы никогда не можем установить или определить начальное
условие с абсолютной точностью. Всегда есть какие-то погрешности, и нам важно
понимать, как эти погрешности повлияют на выводы, которые мы сделаем из нашей
модели. Например, если мы выясним, что траектории, стартующие близко к нулю, со
временем уходят далеко от нулевого решения, это будет означать, что само нулевое
решение не имеет «предсказательной силы» на длительных промежутках времени.

\figure \showcode \collapsed
    \pythonfigure \style max-width: 450px;
        plt.figure(figsize=(6, 12))
        rhss = [lambda t, x: 0.4 * x,
               lambda t, x: -x,
               lambda t,x: x*np.cos(t)]
        for i, rhs in enumerate(rhss):
            plt.subplot(311 + i)
            ob.axes4x4()
            for x0 in [1, 0.5, -0.5, 0]:
                ob.eulersplot(rhs, -3, 4, x0,color='red',lw=2)
            plt.text(-3,1,"$x_0$", fontsize=20)
            plt.text(-3,0, "$t_0$", fontsize=20, horizontalalignment='right',
                    verticalalignment="bottom")
            plt.plot([-3, -3], [-4, 4], lw=2, color='blue')
            # plt.text(2, 3, "$\\\\varphi(t_1;x_0)$", fontsize=20)
            plt.plot([2, 2], [-4, 4], lw=2, color='blue')
    \caption Различное поведение решений, близких у нулевому

Итак, нас интересует поведение решения с начальным условием $x(t_0)=x_0$ при $x_0$ близком к нулю. Будем считать, что на интересующем нас промежутке времени решение убежит от нуля не слишком сильно. В этом случае можно считать, что
\equation
    f(t, x)  \approx f'_x(t, 0) x.
Это следует из определения частной производной функции $f$ по переменной $x$ и
того факта, что $f(t, 0)=0$ для всех $t$. (Мы просто зафиксировали $t$ и стали
смотреть на функцию $f(t, x)$ как на функцию только от аргумента $x$, приблизив
её график соответствующей касательной.)

Пользуясь этим соотношением, заменим в уравнении \ref{eq:9:1d} правую часть на
$f'_x(t, 0) x$. Поскольку правая часть меняется «не слишком сильно» вблизи
прямой $x=0$, разумно ожидать, что и решения, проходящие близко к нулю, от этого
«не слишком сильно» изменятся. Однако, чтобы всё-таки помнить о том, что перед
нами новое уравнение, связанные с исходным лишь приближёнными равенствами,
заменим обозначение для неизвестной функции: вместо $x$ будем писать $y$. Имеем:

\equation
    \label{eq:9:1d-lin}
    \dot y = f'_x(t, 0) y.
Получившееся уравнение гораздо проще исходного и его можно решить явно: это
\snref{уравнение с разделяющимися переменными}. Действительно, функция $f'_x(t,
0)$ зависит только от $t$ и мы мгновенно получаем:

\align
    \item \frac{dy}{dt} & = f'_x(t, 0) y
    \item \frac{dy}{y} & = f'_x(t, 0)
    \item \int_{y_0}^y \frac{d\xi}{\xi} & = \int_{t_0}^t f'_x(\tau, 0) \, d\tau
    \item \ln (y/y_0) & = \int_{t_0}^t f'_x(\tau ,0)\, d\tau 
    \item y & = y_0 \exp \int_{t_0}^t f'_x(\tau, 0) \, d\tau
Получающееся решение $y(t)$ является приближением к решению исходного уравнения.
Например, оно показывает, что  если производная $f'_x$ положительна и отделена от нуля, то есть
$f'_x(t, 0)>c>0$ при всех $t$, то любое решение, близкое к нулевому, убегает от
нулевого, как говорят, с экспоненциальной скоростью ($y(t) > e^{ct} y_0$). Даже
если $y_0$ очень мал, такое решение со временем окажется далеко от нулевого.

Уравнение \ref{eq:9:1d-lin} является не просто уравнением с разделяющимися
переменными. Оно является \emph{линейным} уравнением — и, как говорят,
\emph{линеаризацией} уравнения \ref{eq:9:1d} вблизи решения $x\equiv 0$.

\h3 Более строгое обоснование возможности линеаризации
Этот параграф можно смело пропустить и сразу перейти к \ref[следующему разделу\nonumber|sec:9:notion-of-linear-ode]. Он содержит более аккуратное обоснование
связи между уравнениями \ref{eq:9:1d} и \ref{eq:9:1d-lin}. Для дальнейшего нам
пока это не понадобится.

Зафиксируем какое-нибудь $t_1>t_0$. Нас интересует отображение, которое ставит в соответствие точке $x_0$ точку $\varphi(t_1;x_0)$. Точнее, нас интересует, как эта функция ведёт себя при $x_0$ близких к нулю.

В одномерном случае ответ на вопрос «как ведёт себя функция в точке» даётся производной этой функцией в данной точке. Её-то мы и хотим найти.

Будем действовать смело и решительно. Пусть 

\eq
    y(t)=\left.\frac{\partial \varphi(t;x_0)}{\partial x_0}\right|_{x_0=0}

\question Чему равно $y(t_0)$?

Ответим на более сложный вопрос: что вы можете сказать про знак $y(t_1)$? Очевидно, $y(t_1)>0$, поскольку $\varphi(t_1;x_0)$ является возрастающей по $x_0$. Действительно, если предположить, что существуют точки $x_0^2>x_0^1$ такие, что $\varphi(t_1;x_0^2)<\varphi(t_1;x_0^1)$, по теореме о промежуточном значении найдётся такая точка $t_*\in (t_0, t_1)$, что $\varphi(t_*;x_0^2)=\varphi(t_*,x_0^1)$ (см. \ref[рис.|fig:9:impossible]). А это бы противоречило \snref[теореме существования и единственности] решения дифференциального уравнения. 

\figure \label fig:9:impossible \showcode \collapsed
    \pythonfigure
        plt.figure(figsize=(8,6))
        ob.axes4x4()
        
        for x0 in [1]:
            ob.eulersplot(lambda t,x: x*np.cos(t), -3, 4, x0,color='red',lw=2)
        ob.mplot(np.linspace(-3,4), 
                 lambda x: np.cos(0.5*(x+3))*2, 
                 color='red', lw=2) #fake integral curve
        plt.text(-3,1,"$x_1$", fontsize=20, horizontalalignment='right')
        plt.text(-3,2,"$x_2$", fontsize=20, horizontalalignment='right')
        plt.text(-3,0,"$t_0$", fontsize=20, horizontalalignment='right',
                 verticalalignment="bottom")
        plt.plot([-3, -3], [-4, 4], lw=2, color='blue')
        plt.text(2, 3, "$\\\\varphi(t_1;x_1)$", fontsize=20)
        plt.text(2, -1.5, "$\\\\varphi(t_1;x_2)$", fontsize=20)
        plt.plot([2, 2], [-4, 4], lw=2, color='blue')
    \caption Так не бывает: интегральные кривые не умеют пересекаться


Найдём уравнение на производную $y$ по $t$ (получим так называемое \em{уравнение в вариациях} в его простейшей форме):

\eq
    \dot y= \frac{d}{d t} 
        \left.\frac{\partial \varphi(t;x_0)}{\partial x_0}\right|_{x_0=0} = 
        \left.\left(\frac{\partial}{\partial x_0} 
            \frac{d\varphi(t;x_0)}{dt}\right)\right|_{x_0=0} =
        \left.\left(\frac{\partial}{\partial x_0} 
            f(\varphi(t;x_0),t)\right)\right|_{x_0=0}=
        \left.\left(\frac{\partial f}{\partial x}\right)\right|_{x=0} 
        \left.\frac{\partial \varphi(t;x_0)}{\partial x_0}\right|_{x_0=0}=
        f'_x(0,t) y(t)

Обоснованность смены порядка дифференцирования мы сейчас обсужать не будем (хотя вообще это надо сделать). Записанное уравнение называется \em{уравнением в вариациях по начальному условию}.

Получается, что уравнение на производную по начальному условию имеет вид
\eq
    \dot y=a(t)y
Как мы узнаем чуть ниже, это пример простейшего линейного уравнения.

\h2 Понятие линейного дифференциального уравнения
    \label sec:9:notion-of-linear-ode

Бывают \em{линейные дифференциальные операторы}. Это такая штука, которая действует на функциях, содержит какие-то там производные и ко всему прочему линейная. Вместо того, чтобы давать строгое определение, приведём несколько примеров.

\example
    Пусть $\ph\colon \mathbb R \to \mathbb R$ — некоторая дифференцируемая
    функция.
    \itemize
        \item $(D \ph)(t) = \frac{d}{dt}\ph(t)$ — простейший линейный
            дифференциальный оператор (это просто оператор дифференцирования, он
            линеен, поскольку дифференцирование линейно: производная сумма равна
            сумме производных, константу можно выносить за знак
            дифференцирования). Можно написать, что $D = \frac{d}{dt}$.
        \item $(D\ph)(t)=\frac{d}{dt}\ph(t)-a(t)\ph(t)$ — также линейный дифференциальный оператор. Можно написать, что $D=\frac{d}{dt} - a$, подразумевая, что $a$ — это оператор умножения на функцию $a$.
        \item $(S\ph)(t)=\frac{d}{dt} \ph(t)+a(t)$ не является линейным
            оператором. (Почему?)
        \item $(H\ph)(t)=\frac{d}{dt} \ph(t)+\ph^2(t)$ также не является линейным
            оператором. (Почему?)

    Пусть теперь $\ph\colon \mathbb R \to \mathbb R^n$ — некоторая
    дифференцируемая вектор-функция

    Тогда $(D\ph)(t)=\frac{d\ph(t)}{dt}-A\ph(t)$ — линейный дифференциальный оператор
    (здесь $A$ — некоторый фиксированный линейный оператор $A\colon \mathbb
    R^n\to \mathbb R^n$).

\snippet \label snip:linear \flabel линейное дифференциальное уравнение
    \definition \label def:9:linear
        \emph{Однородное линейное дифференциальное уравнение} — это уравнение вида

        \equation \label eq:9:linear-homog
            Dx=0,
        где $D$ — некоторый линейный дифференциальный оператор.

        \emph{Неоднородное} линейное дифференциальное уравнение — это уравнение вида

        \equation \label eq:9:linear-nonhomog
            Dx=b(t).

\remark 
    В теории дифференциальных уравнений слово \em{однородное} встречается в двух
    разных контекстах. С одной стороны, это представленное выше уравнение
    \ref{eq:9:linear-homog}, у которого в правой части стоит 0. Второй смысл
    слово «однородное»: это уравнение вида $\dot x = F(x/t)$. Такие уравнения
    также изучаются в нашем курсе (они решаются с помощью замены $z = x/t$), но
    они не имеют никакого отношения к линейным однородным уравнениям. Не путайте
    эти два использования одного слова!

Как подсказывает нам мотивирующий пример, чтобы исследовать линеаризацию решения надо исследовать линейные дифференциальные уравнения. Этим мы и займёмся.

\h3 Простейшие свойства линейных уравнений
Для начала сформулируем две простые теоремы о линейных уравнениях. Вообще-то
это теоремы из линейной алгебры: они не используют ничего, кроме линейности.

\theorem
    Множество всех решений автономного линейного дифференциального уравнения —
    линейное пространство.

\proof 
    Нам нужно доказать, что 1) сумма решений
    является решением; 2) умноженное решение на число — тоже решение. Пусть $x$
    и $y$ — решения, $\lambda$ — константа. Тогда $D(x+y)=Dx+Dy=0+0=0$. То есть сумма решений является решением. Аналогично с константой: $D(\lambda x)=\lambda Dx=0$.

\theorem 
    Множество всех решений неавтономного линейного дифференциального уравнения —
    аффинное пространство — то есть линейное, сдвинутое на фиксированный вектор.

    Более точно: для любого дифференциального уравнения
    \ref{eq:9:linear-nonhomog} найдётся такое \em{частное решение} $x^*(t)$
    любое другое решение этого уравнения представляется в виде $x^*(t)+x^0(t)$,
    где $x^0(t)$ — некоторое решение соответствующего однородного уравнения
    \ref{eq:9:linear-homog}. (По правде говоря, в качестве частного решения
    можно взять любое решение неоднородного уравнения.)

\proof
    Пусть $x^1(t)$ — фиксированное решение решение, $x^2(t)$ какое-то другое
    решение. Пусть $x^0=x^2-x^1$. Тогда $D(x^0)= D(x^2-x^1)=D(x^2)-D(x^1)=b-b=0$.
    Таким образом, $x^0$ — решение однородного уравнения, и любое решение $x^2$
    представляется в виде суммы $x^1$ и какого-то решения однородного уравнения
    $x^0$.

    Наоборот, если $x^0$ — решение однородного уравнения, то прибавляя его к
    решению $x^1$ неоднородного уравнения получим какое-то другое решение
    неоднородного уравнения. 

\h3 Как решать неоднородные уравнения: метод вариации постоянных
    \label par:9:constant-variations

Сейчас мы будем делать то, что нельзя: менять постоянные.

Пусть $x(t)\in \mathbb R$. Рассмотрим уравнение
\eq
    \dot x-a(t)x=b(t)
Это уравнение называется \emph{линейным неоднородным дифференциальным уравнением первого порядка в размерности 1 с переменными коэффициентами} («первого порядка» потому что участвует только первая производная).

Как его решить? Решим сперва соответствующее однородное уравнение

\eq
    \dot x-a(t)x=0

Его решение, как мы уже сказали, такое:

\eq
    x^0(t)=Ce^{\int_{t_0}^t a(s) ds}

Скажем теперь, что $C$ — не константа, а функция от времени. И подставим функцию

\eq
    x(t)=C(t)e^{\int_{t_0}^t a(s) ds}

в исходное уравнение.

Получается:

\eq
    \dot C e^{\int_{t_0}^t a(s) ds}+Ca(t)e^{\int_{t_0}^t a(s) ds}=a(t)Ce^{\int_{t_0}^t a(s) ds}+b(t)

Два слагаемых магическим образом сокращаются, и получается уже простое уравнение на $C$:

\eq
    \dot C=b(t)e^{-\int_{t_0}^t a(s) ds}

решая его, имеем:

\eq
    C(t)=\int_{t_0}^ t b(h)e^{-\int_{h_0}^h a(s) ds} dh+C^0

\question 
    Что будет, если попытаться применить метод вариации постоянных к нелинейному
    уравнению — например, $\dot x=x^2+t$?
